{
  "id": 11197,
  "title": "Build a RAG system by uploading PDFs to the Google Gemini File Search Store",
  "slug": "build-a-rag-system-by-uploading-pdfs-to-the-google-gemini-file-search-store-11197",
  "description": "This workflow implements a Retrieval-Augmented Generation (RAG) system usingGoogle Gemini's File Search API. It allows users to upload files to a dedicatedsearch store and then ask questions about their content in a chat interface.The system automatically retrieves relevant information from the uploaded filesto provide accurate, context-aware answers.--------------------------------------------------------------------------------KEY ADVANTAGES1. ✅ Seamless Integration of File Upload + AI ContextThe workflow automates the entire lifecycle: * Upload file * Index file * Retrieve content for AI chatEverything happens inside one n8n automation, without manual actions.2. ✅ Automatic Retrieval for Every User QueryThe AI agent is instructed to always query the Search Store.This ensures: * More accurate answers * Context-aware responses * Ability to reference the exact content the user has uploadedPerfect for knowledge bases, documentation Q&A, internal tools, and support.3. ✅ Reusable Search Store for Multiple SessionsOnce created, the Search Store can be reused: * Multiple files can be imported * Many queries can leverage the same indexed dataA sustainable foundation for scalable RAG operations.4. ✅ Visual and Modular Workflow DesignThanks to n8n’s node-based flow: * Each step is clearly separated * Easy to debug * Easy to expand (e.g., adding authentication, connecting to a database, notifications, etc.)5. ✅ Supports Both Form Submission and Chat MessagesThe workflow is built with two entry points: * A form for uploading files * A chat-triggered entry point for RAG conversationsMeaning the system can be embedded in multiple user interfaces.6. ✅ Compliant and Efficient Interaction With Gemini APIsYour workflow respects the structure of Gemini’s File Search API: * /fileSearchStores (create store) * upload endpoint * importFile endpoint * generateContent with file search toolsThis ensures compatibility and future expandability.7. ✅ Memory-Aware ConversationsWith the Memory Buffer node, the chat session preserves context acrossmessages—providing a more natural and sophisticated conversational experience.--------------------------------------------------------------------------------HOW IT WORKSSTEP 1 - CREATE A NEW SEARCH STORETriggered manually via the “Execute workflow” node, this step sends a request tothe Gemini API to create a FileSearch Store, which acts as a private vectorindex for your documents. * The store name is then saved using a Set node. * This store will later be used for file import and retrieval.STEP 2 - UPLOAD AND IMPORT A FILE INTO THE SEARCH STOREWhen the form is submitted (through the Form Trigger), the workflow: 1. Accepts a file upload via the form. 2. Uploads the file to Gemini using the /upload endpoint. 3. Imports the uploaded file into the Search Store, making it searchable.This step ensures content is stored, chunked, and indexed so the AI model canretrieve relevant sections later.STEP 3 - RAG-ENABLED CHAT WITH GOOGLE GEMINIWhen a chat message is received: * The workflow loads the Search Store identifier. * A LangChain Agent is used along with the Google Gemini Chat Model. * The model is configured to always use the SearchStore tool, so every user query is enriched by a search inside the indexed files. * The system retrieves relevant chunks from your documents and uses them as context for generating more accurate responses.This creates a fully functioning RAG chatbot powered by Gemini.--------------------------------------------------------------------------------SET UP STEPSBefore activating this workflow, you must complete the following configuration: 1. Google Gemini API Credentials: Ensure you have a valid Google AI Studio API key. This key must be entered in all HTTP Request nodes (Create Store, Upload File, Import to Store, and SearchStore). 2. Configure the Search Store: * Manually trigger the \"Create Store\" node once via the \"Execute Workflow\" button. This will call the Gemini API to create a new File Search Store and return its resource name (e.g., fileSearchStores/my-store-12345). * Copy this resource name and update the \"Get Store\" and \"Get Store1\" Set nodes. Replace the placeholder value fileSearchStores/my-store-XXX in both nodes with the actual name of your newly created store. 3. Deploy Triggers: For production use, you should activate the workflow. This will generate public URLs for the \"On form submission\" node (for file uploads) and the \"When chat message received\" node (for the chat interface). These URLs can be embedded in your applications (e.g., a website or dashboard).Once these steps are complete, the workflow is ready. Users can start uploadingfiles via the form and then ask questions about them in the chat.--------------------------------------------------------------------------------NEED HELP CUSTOMIZING?Contact me [/cdn-cgi/l/email-protection#4d24232b220d237e3a632439] for consultingand support or add me on Linkedin [https://www.linkedin.com/in/davideboizza/].",
  "metadescription": "Effortlessly upload and index files for precise, AI-powered answers with Google Gemini's File Search API. Streamline Q&A—learn more now!",
  "summary": "Effortlessly upload and index files for instant, AI-powered Q&A using Google Gemini’s File Search API.\n\nSeamlessly handles file upload, indexing, and contextual retrieval in a single automation—no manual steps required.\n\nEnriches every chat query with real-time, relevant content from your uploaded documents for precise answers.\n\nSupports both file upload forms and chatbot entry points, perfect for knowledge bases, documentation, and support.\n\nReusable search stores let you scale and manage multiple files and sessions with ease.\n\nModular, visually clear node-based workflow is easy to debug and expand.\n\nConversation memory ensures natural, context-rich chat experiences.\n\nFully compliant with Gemini API endpoints; future-proof for upgrades and integrations.",
  "date": "24 Nov 2025",
  "createdAtRaw": "2025-11-24T17:48:06.653+00:00",
  "categories": [
    "Internal Wiki",
    "AI RAG"
  ],
  "nodeTypes": [
    "n8n-nodes-base.set",
    "n8n-nodes-base.merge",
    "n8n-nodes-base.stickyNote",
    "n8n-nodes-base.formTrigger",
    "n8n-nodes-base.httpRequest",
    "n8n-nodes-base.manualTrigger",
    "@n8n/n8n-nodes-langchain.agent",
    "n8n-nodes-base.httpRequestTool",
    "@n8n/n8n-nodes-langchain.chatTrigger",
    "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
    "@n8n/n8n-nodes-langchain.memoryBufferWindow"
  ],
  "author": {
    "name": "Davide",
    "username": "n3witalia",
    "avatar": "https://gravatar.com/avatar/d41b8a0aa81139243509c58870f5b4be292824a507ab57d10ed066d8628ed8da?r=pg&d=retro&size=200",
    "verified": true
  },
  "popularity": 172,
  "visitors": 489,
  "inserters": 189,
  "templateUrl": "https://n8n.io/workflows/11197",
  "readme": "",
  "thumbnail": "https://supabase.amastuces.com/storage/v1/object/public/worklowscreenshot/11197-build-a-rag-system-by-uploading-pdfs-to-the-google-gemini-file-search-store.webp",
  "complexityLevel": "advanced",
  "templateData": null,
  "price": 0,
  "referalUrl": null
}